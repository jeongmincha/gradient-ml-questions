# 05. 제약화 (Regularization)에 대한 다음 물음들에 대해 답하여라.

- 많은 변수가 포함된 모형이 가장 좋다고 할 수 있는가? 아니라면 그 이유는 무엇인가?
  - 그렇지 않다. 변수가 너무 적은 모형은 복잡한 패턴을 가진 데이터를 처리할 수 없다. 그러나 처리해야 할 데이터보다 과하게 많은 변수를 가진 모형은 오히려 과적합 현상을 불러 들일 수 있다. 
- 전진 선택 (Forward Selection) 법과 후진 제거 (Backward Elimination) 법에 대해 설명하라.
  - 전진 선택법은 변수를 하나씩 추가하면서 모형을 테스트하는 방법이고, 후진 제거법은 변수를 하나씩 제거하면서 모형을 테스트하는 방법이다.
- Regularization이란 무엇인가? 변수 선택과 Regularization의 관계에 대해 설명하라.
  - 모형을 훈련시킬 때 쓰이는 비용 함수 (cost function) 에 계수에 대한 패널티 항을 추가함으로써 오버핏을 막는 기법을 Regularization이라고 한다. 패널티 항이 추가되면, 계수가 많아지고 계수의 절댓값이 커질수록 에러가 커진다. 따라서 많은 변수가 포함되어 오버핏을 일으킬 가능성이 큰 모형이 선택에서 배제될 가능성이 커진다.
- L1 Regularization과 L2 Regularization에 대해 설명하라.
  - 이 두 기법의 유일한 차이는 비용 함수에 추가하는 계수 패널티 항의 형태이다.
  - L1 Regularization은 계수들의 절대값의 합에 lambda를 곱한 항을 비용 함수에 추가한다.
  - L2 Regularization은 계수들의 제곱의 합에 lambda를 곱한 항을 비용 함수에 추가한다.